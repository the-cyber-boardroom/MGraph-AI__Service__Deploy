# Brief for MGraph-AI Service Deploy

**Version**: v0.7.0  
**Document Type**: Technical Implementation Brief for LLM Agents  
**Last Updated**: December 2025

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Strategic Context](#2-strategic-context)
3. [Architecture Overview](#3-architecture-overview)
4. [Core Concepts](#4-core-concepts)
5. [Design Decisions & Rationale](#5-design-decisions--rationale)
6. [The Two Graphs Model](#6-the-two-graphs-model)
7. [Tag-Based Resource Discovery](#7-tag-based-resource-discovery)
8. [Operations Architecture](#8-operations-architecture)
9. [Schema Architecture](#9-schema-architecture)
10. [Service Interactions](#10-service-interactions)
11. [Storage Strategy](#11-storage-strategy)
12. [Execution Engine](#12-execution-engine)
13. [API Routes](#13-api-routes)
14. [File Structure](#14-file-structure)
15. [Implementation Phases](#15-implementation-phases)
16. [Testing Strategy](#16-testing-strategy)
17. [Code Style Guidelines](#17-code-style-guidelines)
18. [Success Criteria](#18-success-criteria)

---

## 1. Executive Summary

### 1.1 What Is This?

MGraph-AI Service Deploy is an **API-driven infrastructure orchestration service** that provides the capabilities of CloudFormation/Terraform through a stateless, encrypted-credentials REST API. It orchestrates deployments across multiple cloud providers (AWS, GitHub, and future providers) using atomic operations defined in an MGraph execution graph.

### 1.2 Why Does This Exist?

Traditional IaC tools (CloudFormation, Terraform) are:
- CLI-based, requiring local installation
- File-based, requiring access to state files
- Single-tenant, with credentials stored locally or in CI systems
- Opaque, with limited visibility into execution flow

This Deploy Service is:
- **API-first**: Every operation is a REST call
- **Multi-tenant**: Credentials provided per-request (encrypted), no server-side storage
- **Graph-based**: Execution plan is an MGraph, providing audit trail, parallelism, and resumability
- **Composable**: Built on independent microservices (GitHub Service, AWS Service, Graph Service, Cache Service)
- **Verifiable**: Built-in verification layer to test infrastructure state after each operation

### 1.3 Key Capabilities

| Capability | Description |
|------------|-------------|
| **Deploy** | Create resources across AWS, GitHub |
| **Update** | Modify existing resources |
| **Delete** | Remove resources cleanly |
| **Move** | Migrate resources between regions (create + verify + delete) |
| **Verify** | Test that infrastructure matches expected state |
| **Plan** | Preview changes without executing (dry run) |
| **Multi-region** | Deploy same resources to multiple AWS regions |
| **Step-by-step** | Execute one operation at a time, or run full speed |
| **Resume** | Continue from failed operation after fixing issues |

### 1.4 Target Repository

`the-cyber-boardroom/MGraph-AI__Service__Deploy`

### 1.5 Sister Services (Dependencies)

| Service | Repository | Purpose |
|---------|------------|---------|
| GitHub Service | `MGraph-AI__Service__GitHub` | GitHub API operations (Secrets, Actions, Repos) |
| AWS Service | `MGraph-AI__Service__AWS` | AWS API operations (Lambda, S3, IAM) |
| Graph Service | `MGraph-AI__Service__Graph` | MGraph storage and manipulation |
| Cache Service | `MGraph-AI__Service__Cache` | Execution logs, intermediate data, deployment files |

---

## 2. Strategic Context

### 2.1 The Problem Being Solved

Currently, infrastructure deployment is done via:
1. Direct OSBot-AWS calls in CI pipelines
2. Custom "deploy helper methods" scattered across projects
3. Manual operations when automation fails

This approach has issues:
- No unified state management
- No verification layer
- Difficult to reproduce deployments
- No audit trail of what was deployed and when
- Hard to move resources between regions/accounts

### 2.2 The Solution

A **Deploy Service** that:
1. Takes a declarative JSON configuration
2. Converts it to an MGraph execution plan
3. Executes operations through provider services (AWS, GitHub)
4. Tracks execution state in a separate graph
5. Stores everything in Cache Service for retrieval and audit
6. Provides verification to confirm infrastructure state

### 2.3 Key Workflows to Support

| Workflow | Description |
|----------|-------------|
| **New Account Setup** | Deploy complete service stack to fresh AWS account |
| **Multi-Region Deploy** | Deploy same resources to multiple regions |
| **Service Deletion** | Clean removal of all resources |
| **Region Migration** | Move service from one region to another |
| **Incremental Update** | Update specific resources without full redeploy |

---

## 3. Architecture Overview

### 3.1 System Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              Client                                          │
│   (CI/CD Pipeline, Developer Tool, Admin UI, LLM Agent)                     │
└─────────────────────────────────┬───────────────────────────────────────────┘
                                  │
                                  │ REST API (JSON + Encrypted Credentials)
                                  ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Deploy Service                                       │
│                                                                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │   Routes    │  │  Execution  │  │    Graph    │  │  Operation  │        │
│  │   (API)     │──│   Engine    │──│   Builder   │──│  Primitives │        │
│  └─────────────┘  └─────────────┘  └─────────────┘  └─────────────┘        │
│                                                                              │
└───────────┬─────────────────┬─────────────────┬─────────────────┬───────────┘
            │                 │                 │                 │
            ▼                 ▼                 ▼                 ▼
    ┌───────────────┐ ┌───────────────┐ ┌───────────────┐ ┌───────────────┐
    │GitHub Service │ │ AWS Service   │ │ Graph Service │ │ Cache Service │
    │               │ │               │ │               │ │               │
    │ • Secrets     │ │ • Lambda      │ │ • Spec Graph  │ │ • Deploy File │
    │ • Actions     │ │ • S3          │ │ • Exec Graph  │ │ • Exec Logs   │
    │ • Repos       │ │ • IAM         │ │ • Querying    │ │ • Outputs     │
    └───────────────┘ └───────────────┘ └───────────────┘ └───────────────┘
            │                 │
            ▼                 ▼
    ┌───────────────┐ ┌───────────────┐
    │   GitHub      │ │     AWS       │
    │   API         │ │     API       │
    └───────────────┘ └───────────────┘
```

### 3.2 Data Flow

```
1. Client submits JSON deployment config
                    │
                    ▼
2. Deploy Service parses and validates
                    │
                    ▼
3. JSON converted to Spec Graph (MGraph)
   - Each resource becomes a node
   - Dependencies become edges
   - Node IDs assigned (Obj_Id format)
                    │
                    ▼
4. Spec Graph stored in Cache Service
   - KEY_BASED strategy for discoverability
   - deploy-id/graph-id as cache_key
                    │
                    ▼
5. Execution Engine processes graph
   - Topological sort for execution order
   - Parallel execution where no edges exist
   - Sequential mode for step-by-step
                    │
                    ▼
6. Each operation calls provider service
   - GitHub Service for secrets, actions
   - AWS Service for Lambda, S3, IAM
   - Tags applied with node-id, edge-id, graph-id
                    │
                    ▼
7. Execution state recorded in Execution Graph
   - Linked to Spec Graph
   - Status, timing, outputs, errors
                    │
                    ▼
8. Logs and outputs stored in Cache Service
   - As data files under main deployment file
                    │
                    ▼
9. Response returned to client
   - Success/failure status
   - Graph references for querying state
```

---

## 4. Core Concepts

### 4.1 The Execution Graph IS the State

Unlike Terraform's state file or CloudFormation's stack, this system uses **MGraph** as the execution state. The graph provides:

- **Audit Trail**: Every operation is a node with timestamps
- **Resumability**: Failed operations are marked, downstream blocked
- **Parallelism**: Nodes without edges can execute concurrently
- **Relationships**: Dependencies explicit as edges
- **Versioning**: Graph Service provides history

### 4.2 Graphs of Graphs (Composite Operations)

Operations can contain sub-operations. "Create Lambda" might involve:
1. Create IAM Role
2. Create Lambda Function
3. Update Lambda Configuration
4. Apply Tags

Each is a separate node in the graph, linked by edges. This is represented as **subgraphs** - a node can reference another graph for its implementation.

```
Main Deploy Graph (graph-id: AAAA1111)
│
├── Node: Create Lambda (node-id: 1111aaaa)
│   │
│   └── references: Lambda Creation Subgraph (graph-id: BBBB2222)
│       │
│       ├── Node: Create IAM Role (node-id: 2222bbbb)
│       ├── Node: Create Function (node-id: 3333cccc) ─edge─from─► 2222bbbb
│       ├── Node: Update Config (node-id: 4444dddd) ─edge─from─► 3333cccc
│       └── Node: Apply Tags (node-id: 5555eeee) ─edge─from─► 4444dddd
│
├── Node: Create S3 Bucket (node-id: 6666ffff)
│
└── Node: Set GitHub Secret (node-id: 7777gggg) ─edge─from─► 1111aaaa
```

### 4.3 Edge Semantics

Edges define **execution order** and enable:

| Edge Pattern | Meaning |
|--------------|---------|
| `A → B` | B must wait for A to complete |
| `A → C, B → C` | C waits for both A AND B (join) |
| No edge between A and B | A and B can run in parallel |
| `A → [pause] → B` | Execution pauses after A, requires manual continue |
| `A → [end]` | Execution stops here (partial deployment) |

### 4.4 Two Graphs: Spec vs Execution

| Aspect | Spec Graph | Execution Graph |
|--------|------------|-----------------|
| **Purpose** | What to deploy | What happened |
| **Mutability** | Immutable once created | Updated during execution |
| **Contents** | Resource definitions, properties | Status, timing, outputs, errors |
| **Nodes** | One per resource | One per execution of resource |
| **Relationship** | — | Links to Spec Graph nodes |

### 4.5 Operations Are Atomic

Each operation:
- Receives all input from Spec Graph + tag-based lookups
- Executes one logical action via provider service
- Returns outputs (or error)
- Updates Execution Graph

Operations should NOT depend on previous operation outputs passed through memory. Instead, they use **tag-based discovery** to find resources created by earlier operations.

---

## 5. Design Decisions & Rationale

### 5.1 JSON Configuration Format

**Decision**: Use JSON for deployment configurations (not YAML).

**Rationale**:
- JSON serializes cleanly to/from Type_Safe classes
- No ambiguity in parsing
- Native Python dict handling
- Graph Service uses JSON internally

### 5.2 Separate Create and Update Operations

**Decision**: Provide distinct create and update operation types.

**Rationale**:
- Many workflows only need updates (more efficient)
- Create can fail if resource exists; update assumes it does
- Clear intent in the Spec Graph
- Different verification strategies

### 5.3 Stop on Failure

**Decision**: Halt execution when any operation fails.

**Rationale**:
- Prevents cascading failures
- Maintains known state
- Failed node marked in Execution Graph
- Downstream nodes marked "blocked"
- Can resume after fixing the issue

### 5.4 Verification as Separate Step

**Decision**: Verification is a distinct operation/workflow, not automatic.

**Rationale**:
- Some deployments don't need verification
- Verification can run independently (health checks)
- Different timing requirements (immediate vs. eventual consistency)
- Keeps operations atomic and simple

**Note**: Each operation primitive includes verification code as part of its implementation, but whether to call it is a separate decision.

### 5.5 Tag-Based Resource Discovery

**Decision**: Use tags (AWS) or naming conventions (GitHub) to find resources, not passed ARNs/IDs.

**Rationale**:
- Operations remain independent and atomic
- No need to pass outputs between operations
- State can be reconstructed by scanning tags
- Works for multi-region (same tags, different regions)
- Enables verification without stored state

See [Section 7](#7-tag-based-resource-discovery) for details.

### 5.6 Graph IDs as Tags

**Decision**: AWS resource tags include `node-id`, `edge-id`, `graph-id` from MGraph.

**Rationale**:
- Unique identification (node-id is Obj_Id, guaranteed unique)
- Traceability to exact operation that created resource
- Can reconstruct entire deployment from AWS tag scan
- Audit trail embedded in infrastructure itself

### 5.7 Orchestration Only

**Decision**: Deploy Service orchestrates but doesn't implement provider logic.

**Rationale**:
- Provider services (AWS, GitHub) have the implementation
- Deploy Service focuses on graph execution
- Clean separation of concerns
- Provider services can be used independently
- Easier testing and maintenance

---

## 6. The Two Graphs Model

### 6.1 Spec Graph (Deployment Specification)

The Spec Graph defines **what** should be deployed. Created from JSON config, immutable once created.

**Node Types**:
```
Schema__Deploy__Node__Resource
├── node_id        : Obj_Id                    # Auto-assigned, used for tags
├── resource_type  : Enum__Resource__Type      # aws:lambda, github:secret, etc.
├── operation      : Enum__Operation__Type     # create, update, delete
├── properties     : dict                      # Resource-specific config
├── references     : Dict[str, str]            # {role: "execution-role"} → by resource_id
├── tags           : Dict[str, str]            # Additional custom tags
└── subgraph_id    : Graph_Id = None           # If this is a composite operation
```

**Edge Types**:
```
Schema__Deploy__Edge__Dependency
├── edge_id        : Obj_Id
├── from_node_id   : Obj_Id                    # Predecessor
├── to_node_id     : Obj_Id                    # Successor (waits for predecessor)
└── edge_type      : Enum__Edge__Type          # dependency, pause, end
```

**Example Spec Graph**:
```
Nodes:
  - node_id: 1111aaaa, type: aws:iam:role, operation: create, properties: {...}
  - node_id: 2222bbbb, type: aws:lambda:function, operation: create, 
    properties: {...}, references: {role: "1111aaaa"}
  - node_id: 3333cccc, type: github:secret:repo, operation: create,
    properties: {name: "LAMBDA_ARN", value_from: "2222bbbb.arn"}

Edges:
  - from: 1111aaaa, to: 2222bbbb (lambda needs role)
  - from: 2222bbbb, to: 3333cccc (secret needs lambda ARN)
```

### 6.2 Execution Graph (Execution State)

The Execution Graph records **what happened**. Created during execution, updated as operations complete.

**Node Types**:
```
Schema__Execution__Node
├── node_id            : Obj_Id                # New ID for this execution node
├── spec_node_id       : Obj_Id                # Links to Spec Graph node
├── status             : Enum__Execution__Status
├── started_at         : str                   # ISO timestamp
├── completed_at       : str = None            # ISO timestamp
├── duration_seconds   : float = None
├── outputs            : dict = None           # {arn: "...", id: "..."}
├── error              : str = None            # Error message if failed
└── error_type         : str = None            # Error classification
```

**Status Enum**:
```
Enum__Execution__Status
├── PENDING            # Not yet started
├── RUNNING            # Currently executing
├── COMPLETED          # Successfully finished
├── FAILED             # Error occurred
├── BLOCKED            # Predecessor failed
├── SKIPPED            # Manually skipped
└── PAUSED             # Awaiting manual continue
```

**Edge Types**:
```
Schema__Execution__Edge
├── edge_id        : Obj_Id
├── from_node_id   : Obj_Id
├── to_node_id     : Obj_Id
└── edge_type      : Enum__Execution__Edge__Type  # executed, failed, blocked, skipped
```

### 6.3 Graph Relationship

```
┌─────────────────────────────────────────────────────────────────────┐
│                         Spec Graph                                   │
│                    (graph-id: SPEC1234)                              │
│                                                                      │
│  ┌──────────────┐         ┌──────────────┐         ┌──────────────┐ │
│  │ IAM Role     │────────▶│ Lambda       │────────▶│ Secret       │ │
│  │ (1111aaaa)   │         │ (2222bbbb)   │         │ (3333cccc)   │ │
│  └──────────────┘         └──────────────┘         └──────────────┘ │
│         │                        │                        │         │
└─────────┼────────────────────────┼────────────────────────┼─────────┘
          │ links to               │ links to               │ links to
          ▼                        ▼                        ▼
┌─────────────────────────────────────────────────────────────────────┐
│                       Execution Graph                                │
│                    (graph-id: EXEC5678)                              │
│                                                                      │
│  ┌──────────────┐         ┌──────────────┐         ┌──────────────┐ │
│  │ Exec: Role   │─executed─▶ Exec: Lambda │─blocked──▶ Exec: Secret│ │
│  │ COMPLETED    │         │ FAILED       │         │ BLOCKED      │ │
│  │ outputs:{...}│         │ error:"..."  │         │              │ │
│  └──────────────┘         └──────────────┘         └──────────────┘ │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

---

## 7. Tag-Based Resource Discovery

### 7.1 The Problem

Traditional orchestration passes outputs between steps:
```
Step 1: Create Role → returns ARN: "arn:aws:iam::123:role/my-role"
Step 2: Create Lambda(role_arn="arn:aws:iam::123:role/my-role")
```

This creates tight coupling and makes operations non-atomic.

### 7.2 The Solution: Tag-Based Discovery

Every AWS resource gets standard tags:
```
mgraph:node-id    = "1111aaaa"           # The Spec Graph node ID
mgraph:edge-id    = "4444dddd"           # The edge that triggered creation (optional)
mgraph:graph-id   = "SPEC1234"           # The deployment graph ID
mgraph:deploy-id  = "my-app-prod"        # Human-readable deployment name
mgraph:resource-id = "execution-role"    # Logical name in config
```

Operations find resources by querying tags:
```python
# Instead of passing role_arn
role_arn = aws_service.find_by_tag("mgraph:node-id", "1111aaaa")

# Or by logical name within deployment
role_arn = aws_service.find_by_tags({
    "mgraph:graph-id": "SPEC1234",
    "mgraph:resource-id": "execution-role"
})
```

### 7.3 GitHub Naming Convention

GitHub resources (secrets, repos) don't support tags. Use naming convention:
```
{logical-name}__{node-id}

Examples:
  API_KEY__1111aaaa              # Secret name
  my-app-assets__2222bbbb        # Repo name (if creating)
```

For existing repos/secrets, store mapping in deployment outputs.

### 7.4 S3 Bucket Naming

S3 bucket names must be globally unique. Use node-id suffix:
```
my-app-assets-1111aaaa
```

### 7.5 Tag Resolver Service

```python
class Tag_Resolver(Type_Safe):
    aws_service   : AWS_Service_Client
    graph_id      : str
    
    def find_resource(self, resource_type: str, node_id: str) -> dict:
        """Find AWS resource by node-id tag"""
        # Query AWS for resource with mgraph:node-id = node_id
        ...
    
    def find_by_logical_name(self, resource_type: str, resource_id: str) -> dict:
        """Find AWS resource by logical name within this deployment"""
        # Query AWS for resource with mgraph:graph-id AND mgraph:resource-id
        ...
    
    def get_arn(self, node_id: str) -> str:
        """Get ARN of resource created by spec node"""
        ...
```

---

## 8. Operations Architecture

### 8.1 Operation Primitive

Every operation follows this pattern:

```python
class Operation__Base(Type_Safe):
    spec_node      : Schema__Deploy__Node__Resource    # From Spec Graph
    credentials    : Schema__Provider__Credentials     # Encrypted credentials
    tag_resolver   : Tag_Resolver                      # For finding resources
    
    def validate(self) -> Schema__Validation__Result:
        """Validate operation can execute (pre-flight check)"""
        ...
    
    def execute(self) -> Schema__Operation__Result:
        """Execute the operation"""
        ...
    
    def verify(self) -> Schema__Verification__Result:
        """Verify operation succeeded (optional, called separately)"""
        ...
    
    def rollback(self) -> Schema__Rollback__Result:
        """Undo the operation (future implementation)"""
        ...
```

### 8.2 Operation Result

```python
Schema__Operation__Result
├── success       : bool
├── node_id       : Obj_Id                 # Spec node that was executed
├── outputs       : dict                   # {arn: "...", id: "...", etc.}
├── tags_applied  : Dict[str, str]         # Tags that were set
├── duration      : float                  # Seconds
├── error         : str = None
└── error_type    : Enum__Error__Type = None
```

### 8.3 AWS Operations

| Operation | Provider Call | Tags Applied |
|-----------|---------------|--------------|
| `aws:lambda:create` | AWS Service → Lambda create | All standard tags |
| `aws:lambda:update` | AWS Service → Lambda update | — (already tagged) |
| `aws:lambda:delete` | AWS Service → Lambda delete | — |
| `aws:s3:bucket:create` | AWS Service → S3 create bucket | All standard tags |
| `aws:iam:role:create` | AWS Service → IAM create role | All standard tags |
| `aws:iam:policy:attach` | AWS Service → IAM attach policy | — |

### 8.4 GitHub Operations

| Operation | Provider Call | Naming |
|-----------|---------------|--------|
| `github:secret:repo:create` | GitHub Service → create repo secret | `{name}__{node-id}` |
| `github:secret:repo:update` | GitHub Service → update repo secret | — |
| `github:secret:repo:delete` | GitHub Service → delete repo secret | — |
| `github:action:trigger` | GitHub Service → workflow dispatch | — |

### 8.5 Composite Operations

A composite operation expands into a subgraph:

```python
class Operation__AWS__Lambda__Full_Create(Operation__Base):
    """Creates Lambda with IAM role, config, and tags - expands to subgraph"""
    
    def expand(self) -> MGraph:
        """Generate subgraph of atomic operations"""
        subgraph = MGraph()
        
        # Node 1: Create IAM Role
        role_node = subgraph.add_node(Operation__AWS__IAM__Role__Create, {...})
        
        # Node 2: Create Lambda Function (depends on role)
        lambda_node = subgraph.add_node(Operation__AWS__Lambda__Create, {...})
        subgraph.add_edge(role_node, lambda_node)
        
        # Node 3: Update Lambda Config
        config_node = subgraph.add_node(Operation__AWS__Lambda__Update_Config, {...})
        subgraph.add_edge(lambda_node, config_node)
        
        # Node 4: Apply Tags
        tags_node = subgraph.add_node(Operation__AWS__Lambda__Apply_Tags, {...})
        subgraph.add_edge(config_node, tags_node)
        
        return subgraph
```

---

## 9. Schema Architecture

### 9.1 Deployment Configuration (Input JSON)

```python
Schema__Deploy__Config
├── deployment_id    : Safe_Str__Id              # "my-app-prod"
├── version          : str                        # "v1.2.3"
├── credentials      : Schema__Multi_Provider_Credentials
├── targets          : List[Schema__Deploy__Target]
└── resources        : Dict[str, Schema__Resource__Definition]

Schema__Multi_Provider_Credentials
├── aws              : Schema__AWS__Credentials = None
└── github           : Schema__GitHub__Credentials = None

Schema__AWS__Credentials
├── access_key_id               : str
├── encrypted_secret_access_key : str              # NaCl encrypted
├── encrypted_session_token     : str = None       # NaCl encrypted, optional
├── account_id                  : str = None
└── region                      : str = "us-east-1"

Schema__GitHub__Credentials
├── encrypted_pat    : str                         # NaCl encrypted

Schema__Deploy__Target
├── provider         : Enum__Provider              # aws, github
└── regions          : List[str] = ["us-east-1"]   # For AWS

Schema__Resource__Definition
├── type             : str                         # "aws:lambda:function"
├── operation        : str = "create"              # create, update, delete
├── properties       : dict
├── references       : Dict[str, str] = {}         # {role: "execution-role"}
├── depends_on       : List[str] = []              # ["execution-role"]
└── tags             : Dict[str, str] = {}         # Additional custom tags
```

### 9.2 Example Configuration JSON

```json
{
  "deployment_id": "my-app-prod",
  "version": "v1.2.3",
  "credentials": {
    "aws": {
      "access_key_id": "AKIAIOSFODNN7EXAMPLE",
      "encrypted_secret_access_key": "base64-nacl-encrypted...",
      "region": "us-east-1",
      "account_id": "123456789012"
    },
    "github": {
      "encrypted_pat": "base64-nacl-encrypted..."
    }
  },
  "targets": [
    {"provider": "aws", "regions": ["us-east-1", "eu-west-1"]}
  ],
  "resources": {
    "execution-role": {
      "type": "aws:iam:role",
      "operation": "create",
      "properties": {
        "role_name": "my-app-lambda-role",
        "assume_role_policy": {...},
        "managed_policies": ["arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"]
      }
    },
    "api-lambda": {
      "type": "aws:lambda:function",
      "operation": "create",
      "properties": {
        "function_name": "my-app-api",
        "runtime": "python3.12",
        "handler": "lambda_handler.run",
        "code_s3_bucket": "my-deploy-bucket",
        "code_s3_key": "my-app/v1.2.3/code.zip",
        "memory_size": 256,
        "timeout": 30
      },
      "references": {
        "role": "execution-role"
      },
      "depends_on": ["execution-role"]
    },
    "lambda-arn-secret": {
      "type": "github:secret:repo",
      "operation": "create",
      "properties": {
        "owner": "my-org",
        "repo": "my-app",
        "secret_name": "LAMBDA_ARN"
      },
      "references": {
        "value_from": "api-lambda.arn"
      },
      "depends_on": ["api-lambda"]
    }
  }
}
```

### 9.3 Graph Node Schemas

```python
# Spec Graph Nodes
Schema__Deploy__Node__Resource
├── node_id          : Obj_Id                      # Auto-generated
├── resource_id      : Safe_Str__Id                # Logical name from config key
├── resource_type    : Enum__Resource__Type
├── operation        : Enum__Operation__Type       # create, update, delete
├── properties       : dict
├── references       : Dict[str, str]              # Resolved during execution
├── custom_tags      : Dict[str, str]
├── subgraph_id      : Graph_Id = None             # For composite operations
└── target_regions   : List[str] = []              # For multi-region

# Execution Graph Nodes
Schema__Execution__Node
├── node_id          : Obj_Id                      # Execution node ID
├── spec_node_id     : Obj_Id                      # Links to spec
├── spec_graph_id    : Graph_Id                    # Links to spec graph
├── region           : str                         # Which region (for multi-region)
├── status           : Enum__Execution__Status
├── started_at       : str
├── completed_at     : str = None
├── duration_seconds : float = None
├── outputs          : dict = None                 # {arn, id, name, etc.}
├── tags_applied     : Dict[str, str] = None
├── error            : str = None
├── error_type       : str = None
└── provider_request_id : str = None               # AWS/GitHub request ID
```

### 9.4 Enums

```python
Enum__Provider
├── AWS    = "aws"
└── GITHUB = "github"

Enum__Resource__Type
# AWS Resources
├── AWS_LAMBDA_FUNCTION     = "aws:lambda:function"
├── AWS_LAMBDA_LAYER        = "aws:lambda:layer"
├── AWS_S3_BUCKET           = "aws:s3:bucket"
├── AWS_S3_OBJECT           = "aws:s3:object"
├── AWS_IAM_ROLE            = "aws:iam:role"
├── AWS_IAM_POLICY          = "aws:iam:policy"
├── AWS_IAM_POLICY_ATTACH   = "aws:iam:policy:attach"
# GitHub Resources
├── GITHUB_SECRET_REPO      = "github:secret:repo"
├── GITHUB_SECRET_ENV       = "github:secret:env"
├── GITHUB_SECRET_ORG       = "github:secret:org"
├── GITHUB_ACTION_TRIGGER   = "github:action:trigger"
└── GITHUB_REPO             = "github:repo"

Enum__Operation__Type
├── CREATE   = "create"
├── UPDATE   = "update"
├── DELETE   = "delete"
└── VERIFY   = "verify"

Enum__Execution__Status
├── PENDING   = "pending"
├── RUNNING   = "running"
├── COMPLETED = "completed"
├── FAILED    = "failed"
├── BLOCKED   = "blocked"
├── SKIPPED   = "skipped"
└── PAUSED    = "paused"

Enum__Edge__Type
├── DEPENDENCY  = "dependency"       # Normal execution dependency
├── PAUSE       = "pause"            # Pause execution, wait for continue
└── END         = "end"              # End execution here
```

---

## 10. Service Interactions

### 10.1 GitHub Service Integration

```python
class GitHub_Service_Client(Type_Safe):
    service_url     : str
    
    def create_repo_secret(self, 
                           encrypted_pat  : str,
                           owner          : str,
                           repo           : str,
                           secret_name    : str,
                           secret_value   : str) -> dict:
        """Create repository secret via GitHub Service"""
        payload = {
            "encrypted_pat": encrypted_pat,
            "request_data": {
                "owner": owner,
                "repo": repo,
                "secret_name": secret_name,
                "encrypted_value": self._encrypt_value(secret_value)
            }
        }
        response = self.http_client.post("/github-secrets-repo/create", json=payload)
        return response.json()
    
    # Similar methods for other operations...
```

### 10.2 AWS Service Integration

```python
class AWS_Service_Client(Type_Safe):
    service_url     : str
    
    def create_lambda(self,
                      credentials   : Schema__AWS__Credentials,
                      function_name : str,
                      runtime       : str,
                      handler       : str,
                      role_arn      : str,
                      code_s3_bucket: str,
                      code_s3_key   : str,
                      tags          : Dict[str, str]) -> dict:
        """Create Lambda function via AWS Service"""
        payload = {
            "access_key_id": credentials.access_key_id,
            "encrypted_secret_access_key": credentials.encrypted_secret_access_key,
            "encrypted_session_token": credentials.encrypted_session_token,
            "region": credentials.region,
            "request_data": {
                "function_name": function_name,
                "runtime": runtime,
                "handler": handler,
                "role_arn": role_arn,
                "code_s3_bucket": code_s3_bucket,
                "code_s3_key": code_s3_key,
                "tags": tags
            }
        }
        response = self.http_client.post("/aws-lambda/create", json=payload)
        return response.json()
    
    def find_by_tags(self, resource_type: str, tags: Dict[str, str]) -> list:
        """Find AWS resources by tags"""
        # Uses AWS Resource Groups Tagging API via AWS Service
        ...
```

### 10.3 Graph Service Integration

```python
class Graph_Service_Client(Type_Safe):
    service_url     : str
    namespace       : str = "deploy-service"
    
    def create_graph(self) -> dict:
        """Create new deployment graph"""
        response = self.http_client.post("/graph-crud/create", json={
            "graph_ref": {"namespace": self.namespace},
            "auto_cache": True
        })
        return response.json()["graph_ref"]
    
    def add_resource_node(self, graph_ref: dict, node: Schema__Deploy__Node__Resource) -> dict:
        """Add resource node to spec graph"""
        response = self.http_client.post("/graph-edit/add/node/typed", json={
            "graph_ref": graph_ref,
            "node_type": "Schema__Deploy__Node__Resource",
            "node_data": node.json(),
            "auto_cache": True
        })
        return response.json()
    
    def add_dependency_edge(self, graph_ref: dict, from_node: str, to_node: str) -> dict:
        """Add dependency edge between nodes"""
        response = self.http_client.post("/graph-edit/add/edge/predicate", json={
            "graph_ref": graph_ref,
            "from_node_id": from_node,
            "to_node_id": to_node,
            "predicate": "depends_on",
            "auto_cache": True
        })
        return response.json()
```

### 10.4 Cache Service Integration

```python
class Cache_Service_Client(Type_Safe):
    service_url     : str
    namespace       : str = "deploy-service"
    
    def store_deployment(self, deploy_id: str, graph_id: str, spec_data: dict) -> str:
        """Store deployment spec with discoverable path"""
        cache_key = f"deploys/{deploy_id}/{graph_id}"
        response = self.http_client.post("/store/json/cache-key", json={
            "namespace": self.namespace,
            "strategy": "key-based",
            "cache_key": cache_key,
            "body": spec_data,
            "file_id": "spec.json"
        })
        return response.json()["cache_id"]
    
    def store_execution_log(self, cache_id: str, node_id: str, log_data: dict):
        """Store execution log as child data"""
        self.http_client.post("/data/store/json/with-id-and-key", json={
            "cache_id": cache_id,
            "namespace": self.namespace,
            "data_key": "logs",
            "data_file_id": f"{node_id}.json",
            "body": log_data
        })
    
    def store_outputs(self, cache_id: str, node_id: str, outputs: dict):
        """Store operation outputs as child data"""
        self.http_client.post("/data/store/json/with-id-and-key", json={
            "cache_id": cache_id,
            "namespace": self.namespace,
            "data_key": "outputs",
            "data_file_id": f"{node_id}.json",
            "body": outputs
        })
```

---

## 11. Storage Strategy

### 11.1 Cache Service Structure

```
deploy-service/                              # Namespace
└── data/
    └── key-based/
        └── deploys/
            └── my-app-prod/                 # deployment_id
                └── SPEC1234/                # graph_id
                    │
                    ├── spec.json            # Main file (has cache_id)
                    │   {
                    │     "deployment_id": "my-app-prod",
                    │     "version": "v1.2.3",
                    │     "spec_graph_id": "SPEC1234",
                    │     "exec_graph_id": "EXEC5678",
                    │     "created_at": "...",
                    │     "status": "completed"
                    │   }
                    │
                    └── data/                # Child files
                        ├── spec_graph.json  # Full spec graph export
                        ├── exec_graph.json  # Full execution graph export
                        │
                        ├── logs/
                        │   ├── 1111aaaa.json    # Log per spec node
                        │   ├── 2222bbbb.json
                        │   └── 3333cccc.json
                        │
                        └── outputs/
                            ├── 1111aaaa.json    # Outputs per node
                            └── 2222bbbb.json
```

### 11.2 Discoverable Paths

Find deployment without cache_id:
```python
# By deployment_id and graph_id
cache_key = f"deploys/{deployment_id}/{graph_id}"
result = cache_client.retrieve__cache_key(cache_key, namespace="deploy-service")

# List all deployments
deployments = cache_client.admin_storage().folders("deploys/")

# List all versions of a deployment
versions = cache_client.admin_storage().folders(f"deploys/{deployment_id}/")
```

### 11.3 What Goes Where

| Data Type | Storage | Why |
|-----------|---------|-----|
| Spec Graph | Graph Service + Cache Service | Graph for relationships, Cache for persistence |
| Execution Graph | Graph Service + Cache Service | Same - dual storage for different access patterns |
| Deployment metadata | Cache Service (main file) | Quick lookup by path |
| Execution logs | Cache Service (data/logs/) | Per-node logs, searchable |
| Operation outputs | Cache Service (data/outputs/) | Per-node outputs, for reference resolution |
| Credentials | Memory only | Never persisted |

---

## 12. Execution Engine

### 12.1 Execution Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| **FULL** | Execute all operations as fast as possible | Production deployments |
| **STEP** | Execute one operation, wait for continue | Debugging, manual review |
| **DRY_RUN** | Validate only, no execution | Preview changes |

### 12.2 Execution Flow

```python
class Execution_Engine(Type_Safe):
    spec_graph       : MGraph
    exec_graph       : MGraph
    provider_clients : Dict[str, Any]       # {aws: AWS_Client, github: GitHub_Client}
    tag_resolver     : Tag_Resolver
    cache_client     : Cache_Service_Client
    mode             : Enum__Execution__Mode = "FULL"
    
    def execute(self) -> Schema__Execution__Result:
        """Execute the deployment"""
        # 1. Topological sort of spec graph
        execution_order = self.topological_sort()
        
        # 2. For FULL mode, identify parallelizable groups
        if self.mode == "FULL":
            parallel_groups = self.identify_parallel_groups(execution_order)
        
        # 3. Execute operations
        for group in parallel_groups:
            if self.mode == "FULL":
                # Execute group in parallel
                results = self.execute_parallel(group)
            else:
                # Execute one by one
                for node in group:
                    result = self.execute_node(node)
                    if not result.success:
                        self.mark_downstream_blocked(node)
                        return self.create_failure_result(result)
                    if self.mode == "STEP":
                        return self.create_step_result(result)
        
        return self.create_success_result()
    
    def execute_node(self, spec_node: Schema__Deploy__Node__Resource) -> Schema__Operation__Result:
        """Execute single operation"""
        # 1. Create execution node (status: RUNNING)
        exec_node = self.create_execution_node(spec_node, status="RUNNING")
        
        # 2. Resolve references via tag resolver
        resolved_refs = self.resolve_references(spec_node.references)
        
        # 3. Build operation with resolved data
        operation = self.build_operation(spec_node, resolved_refs)
        
        # 4. Execute via appropriate provider
        try:
            result = operation.execute()
            exec_node.status = "COMPLETED"
            exec_node.outputs = result.outputs
        except Exception as e:
            exec_node.status = "FAILED"
            exec_node.error = str(e)
            result = Schema__Operation__Result(success=False, error=str(e))
        
        # 5. Update execution graph
        self.update_execution_node(exec_node)
        
        # 6. Store log and outputs
        self.cache_client.store_execution_log(self.cache_id, spec_node.node_id, exec_node.to_dict())
        if result.outputs:
            self.cache_client.store_outputs(self.cache_id, spec_node.node_id, result.outputs)
        
        return result
    
    def topological_sort(self) -> List[Obj_Id]:
        """Sort nodes by dependency order"""
        # Standard topological sort using edges
        ...
    
    def identify_parallel_groups(self, order: List[Obj_Id]) -> List[List[Obj_Id]]:
        """Group nodes that can execute in parallel"""
        # Nodes with no edges between them can run together
        ...
    
    def mark_downstream_blocked(self, failed_node: Obj_Id):
        """Mark all nodes that depend on failed node as BLOCKED"""
        ...
```

### 12.3 Reference Resolution

```python
def resolve_references(self, references: Dict[str, str]) -> Dict[str, Any]:
    """Resolve references to actual values"""
    resolved = {}
    
    for key, ref in references.items():
        if "." in ref:
            # Reference to output: "api-lambda.arn"
            node_id, output_key = ref.rsplit(".", 1)
            outputs = self.cache_client.get_outputs(self.cache_id, node_id)
            resolved[key] = outputs.get(output_key)
        else:
            # Reference to resource: "execution-role"
            # Find by tag and return ARN
            resolved[key] = self.tag_resolver.get_arn(ref)
    
    return resolved
```

### 12.4 Pause and Resume

```python
def handle_pause(self, pause_node: Obj_Id):
    """Handle pause edge - wait for manual continue"""
    exec_node = self.get_execution_node(pause_node)
    exec_node.status = "PAUSED"
    self.update_execution_node(exec_node)
    # Store state to cache
    self.cache_client.store_deployment(...)
    # Return to caller - they must call continue_execution()

def continue_execution(self, graph_id: str, from_node: Obj_Id = None):
    """Resume execution from paused state"""
    # Load state from cache
    # Find paused/pending nodes
    # Continue execution
    ...
```

---

## 13. API Routes

### 13.1 Route Overview

| Method | Path | Description |
|--------|------|-------------|
| POST | `/deploy/plan` | Validate config, create graphs, return plan |
| POST | `/deploy/apply` | Execute deployment |
| POST | `/deploy/continue` | Continue paused execution |
| POST | `/deploy/verify` | Verify deployment state |
| POST | `/deploy/destroy` | Delete all resources |
| GET | `/deploy/status/{graph_id}` | Get deployment status |
| GET | `/deploy/history/{deploy_id}` | List deployment versions |
| POST | `/deploy/move` | Move resources between regions |

### 13.2 Request/Response Schemas

**Plan Request**:
```python
Schema__Request__Deploy__Plan
├── config           : Schema__Deploy__Config      # Full deployment config
└── validate_only    : bool = True                 # Don't create graphs
```

**Plan Response**:
```python
Schema__Response__Deploy__Plan
├── success          : bool
├── spec_graph_id    : Graph_Id                    # Created spec graph
├── operations       : List[Schema__Operation__Summary]  # What will be done
├── parallel_groups  : List[List[Obj_Id]]          # Parallelization plan
├── estimated_time   : float                       # Estimated seconds
├── validation_errors: List[str]                   # Any config issues
└── warnings         : List[str]                   # Non-fatal warnings
```

**Apply Request**:
```python
Schema__Request__Deploy__Apply
├── config           : Schema__Deploy__Config      # Full deployment config
├── mode             : Enum__Execution__Mode = "FULL"  # FULL, STEP, DRY_RUN
└── graph_id         : Graph_Id = None             # Resume existing deployment
```

**Apply Response**:
```python
Schema__Response__Deploy__Apply
├── success          : bool
├── graph_id         : Graph_Id
├── cache_id         : Cache_Id
├── status           : Enum__Deployment__Status    # completed, failed, paused
├── operations_completed : int
├── operations_failed    : int
├── operations_pending   : int
├── failed_operation     : Schema__Operation__Summary = None
├── outputs              : Dict[str, dict]         # {node_id: {outputs}}
└── next_operation       : Schema__Operation__Summary = None  # For STEP mode
```

**Status Response**:
```python
Schema__Response__Deploy__Status
├── graph_id         : Graph_Id
├── deployment_id    : str
├── version          : str
├── status           : Enum__Deployment__Status
├── created_at       : str
├── completed_at     : str = None
├── operations       : List[Schema__Operation__Status]
└── spec_graph_ref   : dict                        # Graph service reference
```

### 13.3 Route Implementations

```python
class Routes__Deploy(Fast_API__Routes):
    tag                : str = "deploy"
    execution_engine   : Execution_Engine_Factory
    graph_client       : Graph_Service_Client
    cache_client       : Cache_Service_Client
    
    def plan(self, request: Request, response: Response,
             body: Schema__Request__Deploy__Plan) -> Schema__Response__Deploy__Plan:
        """Create deployment plan from config"""
        # 1. Validate config
        validation = self.validate_config(body.config)
        if validation.errors:
            return Schema__Response__Deploy__Plan(
                success=False, validation_errors=validation.errors
            )
        
        # 2. Build spec graph
        spec_graph = self.build_spec_graph(body.config)
        
        # 3. Calculate execution plan
        engine = self.execution_engine.create(spec_graph, mode="DRY_RUN")
        plan = engine.create_plan()
        
        # 4. If not validate_only, persist graph
        if not body.validate_only:
            graph_ref = self.graph_client.create_graph()
            self.persist_spec_graph(graph_ref, spec_graph)
            spec_graph_id = graph_ref["graph_id"]
        
        return Schema__Response__Deploy__Plan(
            success=True,
            spec_graph_id=spec_graph_id,
            operations=plan.operations,
            parallel_groups=plan.parallel_groups,
            estimated_time=plan.estimated_time
        )
    
    def apply(self, request: Request, response: Response,
              body: Schema__Request__Deploy__Apply) -> Schema__Response__Deploy__Apply:
        """Execute deployment"""
        # 1. Get or create spec graph
        if body.graph_id:
            spec_graph = self.load_spec_graph(body.graph_id)
        else:
            spec_graph = self.build_spec_graph(body.config)
            graph_ref = self.graph_client.create_graph()
            self.persist_spec_graph(graph_ref, spec_graph)
        
        # 2. Create execution engine
        engine = self.execution_engine.create(
            spec_graph=spec_graph,
            credentials=body.config.credentials,
            mode=body.mode
        )
        
        # 3. Execute
        result = engine.execute()
        
        # 4. Return result
        return Schema__Response__Deploy__Apply(
            success=result.success,
            graph_id=result.graph_id,
            cache_id=result.cache_id,
            status=result.status,
            operations_completed=result.completed_count,
            operations_failed=result.failed_count,
            operations_pending=result.pending_count,
            failed_operation=result.failed_operation,
            outputs=result.outputs,
            next_operation=result.next_operation
        )
```

---

## 14. File Structure

```
mgraph_ai_service_deploy/
├── __init__.py
├── config.py                                    # SERVICE_NAME, env vars
│
├── fast_api/
│   ├── __init__.py
│   ├── lambda_handler.py                        # Lambda entry point
│   │
│   ├── routes/
│   │   ├── __init__.py
│   │   ├── Routes__Deploy.py                    # Main deploy routes
│   │   ├── Routes__Info.py                      # Health, status
│   │   └── Routes__Auth.py                      # If needed
│   │
│   └── dependencies/
│       ├── __init__.py
│       └── Service_Clients.py                   # Provider client factory
│
├── schemas/
│   ├── __init__.py
│   │
│   ├── config/                                  # Input configuration schemas
│   │   ├── Schema__Deploy__Config.py
│   │   ├── Schema__Multi_Provider_Credentials.py
│   │   ├── Schema__AWS__Credentials.py
│   │   ├── Schema__GitHub__Credentials.py
│   │   ├── Schema__Deploy__Target.py
│   │   └── Schema__Resource__Definition.py
│   │
│   ├── graph/                                   # Graph node/edge schemas
│   │   ├── Schema__Deploy__Node__Resource.py
│   │   ├── Schema__Deploy__Edge__Dependency.py
│   │   ├── Schema__Execution__Node.py
│   │   └── Schema__Execution__Edge.py
│   │
│   ├── operations/                              # Operation schemas
│   │   ├── Schema__Operation__Result.py
│   │   ├── Schema__Operation__Summary.py
│   │   └── Schema__Verification__Result.py
│   │
│   ├── requests/                                # API request schemas
│   │   ├── Schema__Request__Deploy__Plan.py
│   │   ├── Schema__Request__Deploy__Apply.py
│   │   ├── Schema__Request__Deploy__Continue.py
│   │   ├── Schema__Request__Deploy__Verify.py
│   │   └── Schema__Request__Deploy__Destroy.py
│   │
│   ├── responses/                               # API response schemas
│   │   ├── Schema__Response__Deploy__Plan.py
│   │   ├── Schema__Response__Deploy__Apply.py
│   │   ├── Schema__Response__Deploy__Status.py
│   │   └── Schema__Response__Deploy__History.py
│   │
│   └── enums/                                   # Enumerations
│       ├── Enum__Provider.py
│       ├── Enum__Resource__Type.py
│       ├── Enum__Operation__Type.py
│       ├── Enum__Execution__Status.py
│       ├── Enum__Execution__Mode.py
│       └── Enum__Edge__Type.py
│
├── service/
│   ├── __init__.py
│   │
│   ├── clients/                                 # Provider service clients
│   │   ├── AWS_Service_Client.py
│   │   ├── GitHub_Service_Client.py
│   │   ├── Graph_Service_Client.py
│   │   └── Cache_Service_Client.py
│   │
│   ├── engine/                                  # Execution engine
│   │   ├── Execution_Engine.py
│   │   ├── Execution_Engine_Factory.py
│   │   ├── Graph_Builder.py                     # JSON config → MGraph
│   │   ├── Topological_Sorter.py
│   │   └── Parallel_Grouper.py
│   │
│   ├── operations/                              # Operation primitives
│   │   ├── Operation__Base.py
│   │   │
│   │   ├── aws/
│   │   │   ├── Operation__AWS__Lambda__Create.py
│   │   │   ├── Operation__AWS__Lambda__Update.py
│   │   │   ├── Operation__AWS__Lambda__Delete.py
│   │   │   ├── Operation__AWS__S3__Bucket__Create.py
│   │   │   ├── Operation__AWS__IAM__Role__Create.py
│   │   │   └── ...
│   │   │
│   │   └── github/
│   │       ├── Operation__GitHub__Secret__Repo__Create.py
│   │       ├── Operation__GitHub__Secret__Repo__Update.py
│   │       ├── Operation__GitHub__Action__Trigger.py
│   │       └── ...
│   │
│   └── resolution/                              # Reference resolution
│       ├── Tag_Resolver.py
│       └── Reference_Resolver.py
│
├── utils/
│   └── testing/
│       ├── QA__HTTP_Client.py
│       ├── QA__Deploy_Client.py
│       └── Create_Deploy_Test_Data.py
│
└── deploy/
    └── Deploy__Service.py                       # Lambda deployment
```

---

## 15. Implementation Phases

### Phase 1: Foundation (Week 1-2)

**Objective**: Basic infrastructure and single-operation execution

1. **Project Setup**
   - Repository structure
   - Dependencies (osbot-utils, osbot-fast-api, etc.)
   - Config and environment variables

2. **Schema Foundation**
   - All enum types
   - Config schemas (input JSON)
   - Graph node/edge schemas
   - Request/response schemas

3. **Service Clients**
   - Graph Service client
   - Cache Service client
   - Basic HTTP client wrapper

4. **Basic Routes**
   - `/deploy/plan` (validation only)
   - `/info/health`, `/info/status`

**Deliverables**:
- Working Lambda deployment
- Config validation
- Basic health endpoints

### Phase 2: Graph Building (Week 3-4)

**Objective**: Convert JSON config to executable MGraph

1. **Graph Builder**
   - Parse config JSON
   - Create spec graph nodes
   - Create dependency edges
   - Handle multi-region expansion

2. **Topological Sort**
   - Order operations by dependencies
   - Detect circular dependencies
   - Identify parallel groups

3. **Storage Integration**
   - Store spec graph to Graph Service
   - Store deployment file to Cache Service
   - Discoverable paths (KEY_BASED strategy)

4. **Enhanced Plan Route**
   - Return full execution plan
   - Show parallel groups
   - Estimate execution time

**Deliverables**:
- JSON → MGraph conversion
- Plan endpoint with full details
- Graphs persisted to services

### Phase 3: Execution Engine (Week 5-6)

**Objective**: Execute operations via provider services

1. **AWS Service Client**
   - Lambda operations (create, update, delete)
   - S3 bucket operations
   - IAM role operations
   - Tag-based resource discovery

2. **GitHub Service Client**
   - Secret operations (repo, env, org)
   - Action trigger

3. **Execution Engine**
   - FULL mode (parallel execution)
   - STEP mode (one at a time)
   - DRY_RUN mode (validate only)
   - Execution graph tracking

4. **Apply Route**
   - Full deployment execution
   - Status updates
   - Error handling

**Deliverables**:
- Working `/deploy/apply`
- AWS Lambda deployment via service
- GitHub secrets via service
- Execution state tracking

### Phase 4: Operations Library (Week 7-8)

**Objective**: Complete set of operation primitives

1. **AWS Operations**
   - All Lambda operations
   - All S3 operations
   - All IAM operations
   - Composite operations (Lambda with role)

2. **GitHub Operations**
   - All secret scopes
   - Workflow dispatch
   - Repository operations

3. **Tag Resolver**
   - Find resources by mgraph tags
   - Resolve references between resources
   - Handle multi-region

4. **Verification**
   - Per-operation verify methods
   - Verify endpoint

**Deliverables**:
- Full operation library
- Tag-based discovery
- Verification capability

### Phase 5: Advanced Features (Week 9-10)

**Objective**: Production-ready features

1. **Pause/Resume**
   - Handle pause edges
   - Continue endpoint
   - State persistence

2. **Destroy**
   - Delete all resources
   - Reverse topological order
   - Clean up tags

3. **Move**
   - Create in new region
   - Verify
   - Delete from old region

4. **History**
   - List deployment versions
   - Compare deployments
   - Rollback preparation

**Deliverables**:
- All endpoints working
- Multi-region support
- Full deployment lifecycle

### Phase 6: Testing & Documentation (Week 11-12)

**Objective**: Production quality

1. **Unit Tests**
   - All schemas
   - All operations (mocked)
   - Execution engine

2. **Integration Tests**
   - Real AWS operations
   - Real GitHub operations
   - Full deployment cycles

3. **QA Tests**
   - Against deployed Lambda
   - End-to-end workflows

4. **Documentation**
   - API documentation
   - Usage examples
   - Troubleshooting guide

**Deliverables**:
- Comprehensive test suite
- Full documentation
- Production-ready service

---

## 16. Testing Strategy

### 16.1 Unit Tests

```python
class test_Graph_Builder(TestCase):
    """Test JSON config to MGraph conversion"""
    
    def test_simple_config(self):
        config = Schema__Deploy__Config(...)
        graph = Graph_Builder().build(config)
        assert len(graph.nodes) == 3
        assert len(graph.edges) == 2
    
    def test_dependency_edges(self):
        """Verify edges created for depends_on"""
        ...
    
    def test_multi_region_expansion(self):
        """Verify nodes duplicated per region"""
        ...
```

### 16.2 Integration Tests

```python
class test_Execution_Engine__Integration(TestCase):
    """Test execution with real services"""
    
    @classmethod
    def setUpClass(cls):
        # Skip if no credentials
        # Setup service clients
        ...
    
    def test_create_lambda(self):
        """Create actual Lambda via AWS Service"""
        ...
    
    def test_full_deployment(self):
        """Execute complete deployment workflow"""
        ...
```

### 16.3 QA Tests

```python
class test_Deploy__QA(TestCase):
    """Test against deployed Deploy Service"""
    
    def test_plan_endpoint(self):
        response = self.client.post("/deploy/plan", json={...})
        assert response.status_code == 200
        ...
    
    def test_apply_step_mode(self):
        """Execute deployment one step at a time"""
        ...
```

---

## 17. Code Style Guidelines

Same as other MGraph-AI services:

- **Alignment**: Align equals signs, colons, and comments in visual columns
- **Type Annotations**: Explicit types on all class attributes
- **Comments**: Inline comments (`# comment`) not docstrings
- **Class Names**: `PascalCase` with `__` separating logical groups
- **Route Tags**: `kebab-case` (e.g., `'deploy'`)
- **Context Manager**: Use `with ... as _:` pattern

Example:
```python
class Operation__AWS__Lambda__Create(Operation__Base):
    function_name  : Safe_Str__AWS__Lambda__Name               # Target function name
    runtime        : Enum__Lambda__Runtime                     # Python version
    handler        : str                                       # Entry point
    code_s3_bucket : Safe_Str__AWS__S3__Bucket_Name           # Code location
    code_s3_key    : Safe_Str__AWS__S3__Key                   # Code object key
    
    def execute(self) -> Schema__Operation__Result:            # Execute Lambda creation
        with self.aws_client as _:
            result = _.create_lambda(...)
            return Schema__Operation__Result(success=True, outputs=result)
```

---

## 18. Success Criteria

Implementation is complete when:

1. ✅ `/deploy/plan` validates config and shows execution plan
2. ✅ `/deploy/apply` creates resources across AWS and GitHub
3. ✅ Tag-based resource discovery working (AWS tags, GitHub naming)
4. ✅ Spec Graph and Execution Graph correctly linked
5. ✅ All state persisted to Cache Service with discoverable paths
6. ✅ FULL, STEP, and DRY_RUN modes working
7. ✅ Pause/resume with `/deploy/continue`
8. ✅ `/deploy/verify` confirms infrastructure state
9. ✅ `/deploy/destroy` removes all resources
10. ✅ Multi-region deployment working
11. ✅ Unit tests with mocked services passing
12. ✅ Integration tests with real services passing
13. ✅ QA tests against deployed Lambda passing
14. ✅ OpenAPI documentation auto-generated

---

## Appendix A: Example Deployment Workflow

### A.1 Fresh Account Lambda Deployment

```bash
# 1. Plan
POST /deploy/plan
{
  "config": {
    "deployment_id": "my-app-prod",
    "credentials": {...},
    "resources": {
      "execution-role": {"type": "aws:iam:role", ...},
      "api-lambda": {"type": "aws:lambda:function", "depends_on": ["execution-role"], ...},
      "deploy-secret": {"type": "github:secret:repo", "depends_on": ["api-lambda"], ...}
    }
  }
}

# Response shows: 3 operations, 2 sequential groups, ~45 seconds estimated

# 2. Apply
POST /deploy/apply
{
  "config": {...},
  "mode": "FULL"
}

# Response shows: success, graph_id, outputs (Lambda ARN, etc.)

# 3. Verify
POST /deploy/verify
{
  "graph_id": "...",
  "credentials": {...}
}

# Response shows: all 3 resources verified
```

### A.2 Multi-Region Deployment

```bash
POST /deploy/apply
{
  "config": {
    "deployment_id": "my-app-global",
    "targets": [
      {"provider": "aws", "regions": ["us-east-1", "eu-west-1", "ap-northeast-1"]}
    ],
    "resources": {
      "api-lambda": {"type": "aws:lambda:function", ...}
    }
  }
}

# Creates 3 Lambda functions, one per region, with same tags
```

### A.3 Region Migration

```bash
POST /deploy/move
{
  "deployment_id": "my-app-prod",
  "graph_id": "...",
  "credentials": {...},
  "from_region": "us-east-1",
  "to_region": "eu-west-1",
  "delete_after_verify": true
}

# 1. Creates resources in eu-west-1
# 2. Verifies they work
# 3. Deletes resources from us-east-1
```

---

## Appendix B: Dependencies

```python
LAMBDA_DEPENDENCIES__SERVICE__DEPLOY = [
    'pynacl',                        # Encryption
    'osbot-utils',                   # Type_Safe, utilities
    'osbot-fast-api',                # FastAPI base
    'osbot-fast-api-serverless',     # Lambda deployment
    'requests',                      # HTTP client for service calls
]
```

**Service Dependencies** (runtime, not packaged):
- MGraph-AI Service GitHub (v0.7.0+)
- MGraph-AI Service AWS (v0.1.0+)
- MGraph-AI Service Graph (v1.2.0+)
- MGraph-AI Service Cache (v0.6.0+)